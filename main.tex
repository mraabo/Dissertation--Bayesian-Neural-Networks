\documentclass[a4paper, titlepage, openright]{book}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[fontsize=12.3 pt]{fontsize}
\usepackage{amsmath}
\usepackage[english]{babel}
\usepackage{mathrsfs}
\newread\tmp
% For subplot - does not work...
% \usepackage{graphicx}
% \usepackage{subcaption}
% \usepackage{mwe}

% For blue click-to-go reference
\usepackage[table]{xcolor}
\definecolor{ashgrey}{rgb}{0.7, 0.75, 0.71}
\definecolor{ao(english)}{rgb}{0.0, 0.5, 0.0}

\usepackage{hyperref}
	\hypersetup{
		colorlinks=true,
		linkcolor=blue,
		filecolor=magenta,      
		urlcolor=cyan,
		citecolor=ao(english)
	}
\hypersetup{linktocpage}
\usepackage{floatrow}
% Table float box with bottom caption, box width adjusted to content
\usepackage{multirow}
\newfloatcommand{capbtabbox}{table}[][\FBwidth]

% Keywords command
\providecommand{\keywords}[1]
{
  \small	
  \textbf{\textit{Keywords:}} #1
}
% Nøgleord
\providecommand{\nogleord}[1]
{
  \small	
  \textbf{\textit{Nøgleord:}} #1
}

% For char count
\newcommand{\quickcharcount}[1]{%
  \immediate\write18{texcount -1 -sum -merge -char #1.tex > #1-chars.sum}%
  \openin\tmp=#1-chars.sum%
  \read\tmp to \thechar%
  \closein\tmp%
}

\newcommand{\quickwordcount}[1]{%
  \immediate\write18{texcount -1 -sum -merge #1.tex > #1-words.sum}%
  \openin\tmp=#1-words.sum%
  \read\tmp to \theword%
  \closein\tmp%
}

\usepackage[a4paper, total={6in, 9in}]{geometry}
\usepackage{url}
\usepackage{fancyhdr}
\usepackage[toc,page]{appendix}
\usepackage{amsthm}
\newtheorem{theorem}{Theorem}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{xifthen}
\usepackage{xparse}
\usepackage{dsfont}


% To write pseudo code
\usepackage[ruled,vlined]{algorithm2e}
\SetKwInput{KwInput}{Input}
\SetKwInput{KwOutput}{Output}
\SetKwInput{Function}{function}




\usepackage{neuralnetwork}
\usepackage{lastpage}
\usepackage{natbib}
% -------------- Nomenclature settings ------------
\usepackage[intoc]{nomencl}
\makenomenclature
\renewcommand{\nomname}{Notation}
\renewcommand{\nompreamble}{This section provides a concise reference describing the notation used throughout
this thesis.}
\usepackage{etoolbox}
\renewcommand\nomgroup[1]{%
  \item[\bfseries
  \ifstrequal{#1}{N}{Numbers and Arrays}{%
  \ifstrequal{#1}{S}{Sets and Graphs}{%
  \ifstrequal{#1}{I}{Indexing}{%
  \ifstrequal{#1}{L}{Linear Algebra Operations}{%
  \ifstrequal{#1}{P}{Probability and Information Theory}{%
  \ifstrequal{#1}{D}{Datasets and Distributions}{
  \ifstrequal{#1}{F}{Functions}{}
  }}}}}
  }%
]}
% --------------------------------------------------


% ------- For python-code format and highligting ---
% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{12} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{12}  % for normal

% code listings for python
\usepackage{listings}

\lstdefinestyle{mystyle}{
	language=Python,
	basicstyle=\ttfamily\footnotesize,
	backgroundcolor=\color[HTML]{F7F7F7},
	rulecolor=\color[HTML]{EEEEEE},
	identifierstyle=\color[HTML]{24292E},
	emphstyle=\color[HTML]{005CC5},
	keywordstyle=\color[HTML]{D73A49},
	commentstyle=\color[HTML]{6A737D},
	stringstyle=\color[HTML]{032F62},
	emph={@property,self,range,True,False},
	morekeywords={super,with,as,lambda},
	literate=%
	{+}{{{\color[HTML]{D73A49}+}}}1
	{-}{{{\color[HTML]{D73A49}-}}}1
	{*}{{{\color[HTML]{D73A49}*}}}1
	{/}{{{\color[HTML]{D73A49}/}}}1
	{=}{{{\color[HTML]{D73A49}=}}}1
	{/=}{{{\color[HTML]{D73A49}=}}}1,
	breakatwhitespace=false,
	breaklines=true,
	captionpos=b,
	keepspaces=true,
	numbers=none,
	showspaces=false,
	showstringspaces=false,
	showtabs=false,
	tabsize=4,
	frame=single,
}
\lstset{style=mystyle}

%---------------------------- Macros  -----------------
% Left-right bracket
\newcommand{\lr}[1]{\left (#1\right)}
% Left-right square bracket
\newcommand{\lrs}[1]{\left [#1 \right]}
% Left-right curly bracket
\newcommand{\lrc}[1]{\left \{#1\right\}}
% Left-right absolute value
\newcommand{\lra}[1]{\left |#1\right|}
% Left-right upper value
\newcommand{\lru}[1]{\left \lceil#1\right\rceil}
% Scalar product
\newcommand{\vp}[2]{\left \langle #1 , #2 \right \rangle}
% The real numbers
\newcommand{\R}{\mathbb R}
% The natural numbers
\newcommand{\N}{\mathbb N}
% Expectation symbol with an optional argument
\NewDocumentCommand{\E}{o}{\mathbb E\IfValueT{#1}{\lrs{#1}}}
% Indicator function with an optional argument
\NewDocumentCommand{\1}{o}{\mathds 1{\IfValueT{#1}{\lr{#1}}}}
% Probability function
\let\P\undefined
\NewDocumentCommand{\P}{o}{\mathbb P{\IfValueT{#1}{\lr{#1}}}}
% A hypothesis space
\newcommand{\HH}{\mathcal H}
% A sample space
\newcommand{\XX}{\mathbb{X}}
% A label space
\newcommand{\YY}{\mathbb{Y}}
% A nicer emptyset symbol
\let\emptyset\varnothing
% Sign operator
\DeclareMathOperator{\sign}{sign}
\newcommand{\sgn}[1]{\sign\lr{#1}}
% KL operator
\DeclareMathOperator{\KL}{KL}
% kl operator
\DeclareMathOperator{\kl}{kl}
% The entropy
\let\H\relax
\DeclareMathOperator{\H}{H}
% Majority vote
\DeclareMathOperator{\MV}{MV}
% Variance
\DeclareMathOperator{\V}{Var}
\NewDocumentCommand{\Var}{o}{\V\IfValueT{#1}{\lrs{#1}}}
% VC
\DeclareMathOperator{\VC}{VC}
% VC-dimension
\newcommand{\dVC}{d_{\VC}}
% FAT ...
\DeclareMathOperator{\FAT}{FAT}
\newcommand{\dfat}{d_{\FAT}}
\newcommand{\lfat}{\ell_{\FAT}}
\newcommand{\Lfat}{L_{\FAT}}
\newcommand{\hatLfat}{\hat L_{\FAT}}
% norm
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
%argmin and argmax
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
% Independent
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
% Theorems
\newtheorem{mytheorem}{Theorem}
\numberwithin{mytheorem}{chapter}
% Definitions
\newtheorem{mydefinition}{Definition}

\newcounter{example}[section]
\newenvironment{example}[1][]{\refstepcounter{example}\par\medskip
   \noindent \textbf{Example~\theexample. #1} \rmfamily}{\medskip}

% ----------------------- Layout settings -----------------
\graphicspath{ {./pics/} } 

\renewcommand{\baselinestretch}{1.5}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE]{\nouppercase \leftmark}
\fancyhead[RO]{\nouppercase \rightmark}
\fancyhead[RE,LO]{\thepage}

\numberwithin{equation}{section}

% Remove centered pagenumber from chapter-pages 
\makeatletter
\let\ps@plain\ps@empty
\makeatother

%%%%%% Specificerer linjeafstand. %%%%
%\usepackage{setspace}
%\setstretch{1.2}
%\selectfont

\begin{document}
\quickwordcount{main}
\quickcharcount{main}
\frontmatter
% -------------------------- Front page -----------------------
\begin{titlepage}
%\clearpage
\thispagestyle{empty}
%% temporary titles
\newgeometry{top=0cm, bottom=0cm, outer=2cm, inner=2cm}
% command to provide stretchy vertical space in proportion
\newcommand\nbvspace[1][3]{\vspace*{\stretch{#1}}}
% allow some slack to avoid under/overfull boxes
\newcommand\nbstretchyspace{\spaceskip0.5em plus 0.25em minus 0.25em}
% % To improve spacing on titlepages
\newcommand{\nbtitlestretch}{\spaceskip0.6em}

\begin{center}
\begin{figure}
\begin{center}
\includegraphics[scale=0.55]{pics/CBS.jpg}
\end{center} 
\end{figure}
	\bfseries
	\Huge
	{\nbtitlestretch\huge
	 Bayesian Neural Networks}
	 \nbvspace[1]
	\normalsize
	
	THEORY AND APPLICATIONS\\
	\footnotesize BY\\
	\footnotesize MAGNUS RAABO ANDERSEN (110307) \& ULRIK ROED-SØRENSEN (111931)\\[0.5em]
	\footnotesize SUPERVISOR: PETER DALGAARD
	
	\nbvspace[1]
	
	\includegraphics[width=4in]{pics/neural_network.png}
	\nbvspace[1]
	%\normalsize
	
	MASTER'S THESIS \\ 
	COPENHAGEN BUSINESS SCHOOL --- CAND.MERC.(MAT.)\\
    \nbvspace[1]
    DATE OF SUBMISSION: MAY 17 2021\\
    NUMBER OF PAGES: 103 ($155732 \textnormal{ characters with spaces}$)
	
	\nbvspace[1]
\end{center}
\end{titlepage}
% --------------------------- Main document -------------------
\thispagestyle{empty}


\begin{center}
    \Large
    \textbf{Abstract}
\end{center}
\vspace{0.9cm}
This thesis examines Bayesian inference in neural networks with Markov chain Monte Carlo sampling for performing regression and classification, and how this is different from using non-Bayesian feedforward neural networks. Initially basic machine learning theory for supervised learning algorithms is outlined. This theory is subsequently used for examining how neural networks work, and how they can be trained and regularized. This provides the fundamentals for introducing Bayesian inference and how it can be used for neural networks. The Markov chain Monte Carlo based Bayesian neural networks will be the focal point for this analysis, and we examine the most popular sampling methods for these, while only covering the fundamentals on the choice of prior distributions. Through implementation of different neural networks and Bayesian neural networks we illustrate and evaluate how these perform when predicting house prices using regression and predicting probabilities for default of credit card clients for binary classification.
\\
\\
\keywords{Machine Learning, Neural Networks, Bayesian Neural Network, Deep Learning, TensorFlow, Markov Chain Monte Carlo, Python, Computational Statistics, Hamiltonian Monte Carlo, No-U-Turn Sampler, Bayesian Inference, Mathematics of Computing, Probability and Statistics, Bayesian Deep Learning, Stochastic Neural Network, PyMC3.}

\clearpage
\thispagestyle{empty}
\begin{center}
    \Large
    \textbf{Resumé}
\end{center}
\vspace{0.9cm}
Denne afhandling undersøger Bayesiansk-inferens i neurale netværk med Markov-kæde Monte Carlo-sampling til udførelse af regression og klassifikation, og hvordan dette er forskelligt fra at bruge ikke-Bayesianske feedforward neurale netværk. Først beskrives grundlæggende machine learning teori for supervised læringsalgoritmer. Denne teori bruges efterfølgende til at undersøge, hvordan neurale netværk fungerer, og hvordan de kan trænes og regulariseres. Dette giver de grundlæggende forudsætninger for introduktion af Bayesiansk-inferens i neurale netværk. Markov-kæde Monte Carlo-baserede Bayesianske neurale netværk vil være omdrejningspunktet for denne analyse, og vi undersøger de mest populære sampling-metoder indenfor denne teori, mens der kun dækkes den grundlæggende teori om valget af prior fordelinger. Gennem implementering af forskellige neurale netværk og Bayesianske neurale netværk illustrerer og vurderer vi, hvordan disse fungerer ved prædiktion af huspriser ved hjælp af regression og prædiktion af sandsynligheder for misligholdt gæld af kreditkortklienter til binær klassifikation.
\\
\\
\nogleord{Machine Learning, Neural Networks, Bayesian Neural Network, Deep Learning, TensorFlow, Markov Chain Monte Carlo, Python, Computational Statistics, Hamiltonian Monte Carlo, No-U-Turn Sampler, Bayesian Inference, Mathematics of Computing, Probability and Statistics, Bayesian Deep Learning, Stochastic Neural Network, PyMC3.}

\clearpage
% Har rykket Acknowledgements ind midt på siden ligesom i en bog
\thispagestyle{empty}
\begin{center}
\section*{Acknowledgements}
\end{center}
We owe a special thank you to our supervisor Peter Dalgaard for help and guidance, we are grateful that you have led us in the right direction. Furthermore, we would like to thank Eric J. Ma for increasing our interest in Bayesian neural networks and for being helpful with several questions along the way. We thank Caroline Enersen for providing us with food and sweets. We also thank our families for their love and support. Last but not least we would like to thank Rasmus Nielsen Kollegiet for providing us with a ping pong table for when we needed a break.
\newpage



\tableofcontents \thispagestyle{empty} 

\listoffigures \thispagestyle{empty} \addcontentsline{toc}{chapter}{List of Figures}
\listoftables \thispagestyle{empty} \addcontentsline{toc}{chapter}{List of Tables}
\listofalgorithms
\addcontentsline{toc}{chapter}{List of Algorithms}
\newpage
\include{nomenclature}

\mainmatter
%\setcounter{page}{1}

\include{introduction}


\include{machine_learning_basics}
\include{neural_networks}
\include{bayesian_neural_networks}
\include{eval_NN_models}
\include{conclusion}
\include{for_futureWork}




\bibliographystyle{agsm}
\nocite{*}
\bibliography{bibFile.bib}  % If you have some references, use BibTeX

\include{appendix}

\end{document}