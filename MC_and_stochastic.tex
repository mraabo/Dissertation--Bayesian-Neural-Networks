\chapter{Markov Chains and Stochastic processes}


\section{Stochastic Processes}
In probability theory and Bayesian statistics, a stochastic process is a collection of random variables $\mathbf{x}$, that can be indexed by some index set $\mathbb{A}$. Often we are concerned about how the process evolves over time $T$, and let $t\in T$ be an index or an element of $T$. Then $X_t$ is a the state of a random variable a time $t$ and $\{X(t)\}_{t \in T}$ is used to denote the stochastic process for all $t\in T$. If $t=1,2,\ldots$ then the Stochastic process $\{X(t)\}_{t \in T}$ is said to be discrete and if $T=[0, \infty)$ the process is continuous. Besides an index set, we also have a state space $\mathbb{S}$ which is the set of values that the process can take. $\mathbb{S}$ can also be either continuous or discrete. 

\section{Markov Chains}\label{sec:MarkovChain}



